{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mudit9/DeepLearningMP1/blob/main/Copy_of_DL_MP1_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"ray[tune]\""
      ],
      "metadata": {
        "id": "fo8FM0mczoGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b90f8b6-2223-4fb0-cb80-c8668dca2494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.43.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.2.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.3)\n",
            "Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
            "Requirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.7)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDvxQxTbCpKJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        #self.drop_layer = F.Dropout(p=0.25)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=2)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=1)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=1)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=1)\n",
        "\n",
        "        self.linear = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def project1_model():\n",
        "    #return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "    return ResNet(BasicBlock,[1,1,1,1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler"
      ],
      "metadata": {
        "id": "YVQnTeIlCcrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
        "    #print('here2.5')\n",
        "\n",
        "    net = project1_model()\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if config[\"optimizer\"] == 'sgd':\n",
        "      optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"],momentum=0.9, weight_decay=5e-4)\n",
        "    \n",
        "    if config[\"optimizer\"] == 'adam':\n",
        "      optimizer = optim.Adam(net.parameters(), lr=config[\"lr\"], weight_decay=5e-4)\t\n",
        "    if config[\"optimizer\"] == 'adagrad':\n",
        "      optimizer = optim.Adagrad(net.parameters(), lr=config[\"lr\"],weight_decay=5e-4)\n",
        "    \n",
        "        \n",
        "        \n",
        "    #print('here3')\n",
        "    if checkpoint_dir:\n",
        "        model_state, optimizer_state = torch.load(\n",
        "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "        net.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    trainset, testset = load_data(data_dir)\n",
        "\n",
        "    test_abs = int(len(trainset) * 0.8)\n",
        "    train_subset, val_subset = random_split(\n",
        "        trainset, [test_abs, len(trainset) - test_abs])\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        train_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "    valloader = torch.utils.data.DataLoader(\n",
        "        val_subset,\n",
        "        batch_size=int(config[\"batch_size\"]),\n",
        "        shuffle=True,\n",
        "        num_workers=8)\n",
        "    print('here4')\n",
        "\n",
        "    for epoch in range(25):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        epoch_steps = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            epoch_steps += 1\n",
        "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
        "                                                running_loss / epoch_steps))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # Validation loss\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for i, data in enumerate(valloader, 0):\n",
        "            with torch.no_grad():\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.cpu().numpy()\n",
        "                val_steps += 1\n",
        "\n",
        "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
        "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
        "    print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "I1K_Sy4aon7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir=\"./data\"):\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        #transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, shuffle=False, num_workers=2)\n",
        "\n",
        "    return trainset, testset"
      ],
      "metadata": {
        "id": "ItvqLIFkyRET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(net, device=\"cpu\"):\n",
        "    trainset, testset = load_data()\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "BmAGHjdppXwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mainfunc(num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
        "    data_dir = os.path.abspath(\"./data\")\n",
        "    config = {\n",
        "        \"optimizer\":tune.choice([\"adam\", \"sgd\", \"adagrad\"]),\n",
        "        \"lr\": tune.loguniform(1e-3, 1e-1),\n",
        "        \"batch_size\": tune.choice([16, 64, 128, 256])\n",
        "    }\n",
        "    print('here')\n",
        "    scheduler = ASHAScheduler(\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        max_t=max_num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    reporter = CLIReporter(\n",
        "        parameter_columns=[\"lr\", \"batch_size\",\"optimizer\"],\n",
        "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "    print('here2')\n",
        "\n",
        "    result = tune.run(\n",
        "        tune.with_parameters(train_cifar, data_dir=data_dir),\n",
        "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n",
        "    \n",
        "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
        "    print(\"Best trial config: {}\".format(best_trial.config))\n",
        "    print(\"Best trial final validation loss: {}\".format(\n",
        "        best_trial.last_result[\"loss\"]))\n",
        "    print(\"Best trial final validation accuracy: {}\".format(\n",
        "        best_trial.last_result[\"accuracy\"]))\n",
        "\n",
        "    best_trained_model = project1_model()\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if gpus_per_trial > 1:\n",
        "            best_trained_model = nn.DataParallel(best_trained_model)\n",
        "    best_trained_model.to(device)\n",
        "\n",
        "    best_checkpoint_dir = best_trial.checkpoint.value\n",
        "    model_state, optimizer_state = torch.load(os.path.join(\n",
        "        best_checkpoint_dir, \"checkpoint\"))\n",
        "    best_trained_model.load_state_dict(model_state)\n",
        "\n",
        "    test_acc = test_accuracy(best_trained_model, device)\n",
        "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
      ],
      "metadata": {
        "id": "5njdQoi-pxiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mainfunc(num_samples=7, max_num_epochs=25, gpus_per_trial=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ukX0kxp0y7",
        "outputId": "1132a456-7fdf-41cc-d9aa-5ebb7ee8e6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here\n",
            "here2\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:08:10 (running for 00:00:00.18)\n",
            "Memory usage on this node: 2.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (7 PENDING)\n",
            "+-------------------------+----------+-------+------------+--------------+-------------+\n",
            "| Trial name              | status   | loc   |         lr |   batch_size | optimizer   |\n",
            "|-------------------------+----------+-------+------------+--------------+-------------|\n",
            "| train_cifar_65f1b_00000 | PENDING  |       | 0.00225529 |           64 | sgd         |\n",
            "| train_cifar_65f1b_00001 | PENDING  |       | 0.0247427  |          256 | sgd         |\n",
            "| train_cifar_65f1b_00002 | PENDING  |       | 0.00212884 |          128 | sgd         |\n",
            "| train_cifar_65f1b_00003 | PENDING  |       | 0.00240215 |           16 | sgd         |\n",
            "| train_cifar_65f1b_00004 | PENDING  |       | 0.0096078  |          128 | adam        |\n",
            "| train_cifar_65f1b_00005 | PENDING  |       | 0.00813447 |          128 | adam        |\n",
            "| train_cifar_65f1b_00006 | PENDING  |       | 0.00151213 |          128 | sgd         |\n",
            "+-------------------------+----------+-------+------------+--------------+-------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:08:15 (running for 00:00:05.22)\n",
            "Memory usage on this node: 3.4/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_cifar pid=13062)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_cifar pid=13062)\u001b[0m \r  0%|          | 0/170498071 [00:00<?, ?it/s]\n",
            "  0%|          | 443392/170498071 [00:00<00:42, 4038385.27it/s]\n",
            "  3%|▎         | 4438016/170498071 [00:00<00:06, 24340585.68it/s]\n",
            "  9%|▉         | 15451136/170498071 [00:00<00:03, 44705537.24it/s]\n",
            " 13%|█▎        | 22135808/170498071 [00:00<00:02, 52609639.44it/s]\n",
            " 17%|█▋        | 28141568/170498071 [00:00<00:02, 55125975.34it/s]\n",
            " 21%|██        | 34981888/170498071 [00:00<00:02, 59442395.05it/s]\n",
            " 24%|██▍       | 41440256/170498071 [00:00<00:02, 61073632.96it/s]\n",
            " 28%|██▊       | 48025600/170498071 [00:00<00:01, 62564151.78it/s]\n",
            " 32%|███▏      | 54445056/170498071 [00:01<00:01, 63050470.24it/s]\n",
            " 36%|███▌      | 61309952/170498071 [00:01<00:01, 64745765.61it/s]\n",
            " 40%|████      | 68346880/170498071 [00:01<00:01, 66447232.49it/s]\n",
            " 44%|████▍     | 75840512/170498071 [00:01<00:01, 69016034.33it/s]\n",
            " 49%|████▊     | 82745344/170498071 [00:01<00:01, 66016699.93it/s]\n",
            " 53%|█████▎    | 89704448/170498071 [00:01<00:01, 67056902.13it/s]\n",
            " 57%|█████▋    | 96434176/170498071 [00:01<00:01, 54371365.54it/s]\n",
            " 61%|██████    | 103165952/170498071 [00:01<00:01, 57659991.00it/s]\n",
            " 64%|██████▍   | 109429760/170498071 [00:01<00:01, 58982581.16it/s]\n",
            " 68%|██████▊   | 115742720/170498071 [00:02<00:00, 60124341.20it/s]\n",
            " 72%|███████▏  | 122032128/170498071 [00:02<00:00, 60903773.12it/s]\n",
            " 75%|███████▌  | 128546816/170498071 [00:02<00:00, 62117297.96it/s]\n",
            " 79%|███████▉  | 135043072/170498071 [00:02<00:00, 62938633.80it/s]\n",
            " 83%|████████▎ | 141459456/170498071 [00:02<00:00, 62816359.60it/s]\n",
            " 87%|████████▋ | 148026368/170498071 [00:02<00:00, 63653770.05it/s]\n",
            " 94%|█████████▍| 161104896/170498071 [00:02<00:00, 64141818.27it/s]\n",
            " 98%|█████████▊| 167539712/170498071 [00:02<00:00, 63606442.34it/s]\n",
            "170499072it [00:02, 59793455.11it/s]                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_cifar pid=13062)\u001b[0m Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:08:20 (running for 00:00:10.30)\n",
            "Memory usage on this node: 3.8/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_cifar pid=13062)\u001b[0m Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_cifar pid=13062)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(train_cifar pid=13062)\u001b[0m   cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:34:30 (running for 00:26:20.54)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.50606 |     0.8253 |                   12 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:34:35 (running for 00:26:25.56)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.50606 |     0.8253 |                   12 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:34:40 (running for 00:26:30.60)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.50606 |     0.8253 |                   12 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8277\n",
            "  date: 2022-03-24_05-34-43\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 13\n",
            "  loss: 0.5131143192007284\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1590.202399969101\n",
            "  time_this_iter_s: 122.02479672431946\n",
            "  time_total_s: 1590.202399969101\n",
            "  timestamp: 1648100083\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 13\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:34:45 (running for 00:26:35.90)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:34:50 (running for 00:26:40.93)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:34:55 (running for 00:26:45.96)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:00 (running for 00:26:51.00)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:05 (running for 00:26:56.03)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:10 (running for 00:27:01.05)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:15 (running for 00:27:06.09)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:20 (running for 00:27:11.11)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:26 (running for 00:27:16.14)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:31 (running for 00:27:21.17)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:36 (running for 00:27:26.20)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:41 (running for 00:27:31.24)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:46 (running for 00:27:36.28)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:51 (running for 00:27:41.31)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:35:56 (running for 00:27:46.33)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:01 (running for 00:27:51.36)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:06 (running for 00:27:56.40)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:11 (running for 00:28:01.42)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:16 (running for 00:28:06.45)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:21 (running for 00:28:11.48)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:26 (running for 00:28:16.51)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:31 (running for 00:28:21.53)\n",
            "Memory usage on this node: 3.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:36 (running for 00:28:26.57)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:41 (running for 00:28:31.60)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.513114 |     0.8277 |                   13 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8341\n",
            "  date: 2022-03-24_05-36-43\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 14\n",
            "  loss: 0.48194663198130905\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1709.8668892383575\n",
            "  time_this_iter_s: 119.66448926925659\n",
            "  time_total_s: 1709.8668892383575\n",
            "  timestamp: 1648100203\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 14\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:47 (running for 00:28:37.57)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:52 (running for 00:28:42.60)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:36:57 (running for 00:28:47.64)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:02 (running for 00:28:52.66)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:07 (running for 00:28:57.69)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:12 (running for 00:29:02.73)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:17 (running for 00:29:07.76)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:22 (running for 00:29:12.79)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:27 (running for 00:29:17.83)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:32 (running for 00:29:22.85)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:37 (running for 00:29:27.89)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:42 (running for 00:29:32.92)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:47 (running for 00:29:37.95)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:52 (running for 00:29:42.97)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:37:57 (running for 00:29:48.00)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:02 (running for 00:29:53.03)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:07 (running for 00:29:58.08)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:12 (running for 00:30:03.11)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:18 (running for 00:30:08.13)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:23 (running for 00:30:13.17)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:28 (running for 00:30:18.40)\n",
            "Memory usage on this node: 4.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:33 (running for 00:30:23.43)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:38 (running for 00:30:28.47)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:43 (running for 00:30:33.49)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.481947 |     0.8341 |                   14 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8422\n",
            "  date: 2022-03-24_05-38-45\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 15\n",
            "  loss: 0.4685534289118591\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1832.1853156089783\n",
            "  time_this_iter_s: 122.31842637062073\n",
            "  time_total_s: 1832.1853156089783\n",
            "  timestamp: 1648100325\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 15\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:48 (running for 00:30:38.89)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:53 (running for 00:30:43.91)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:38:58 (running for 00:30:48.94)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:03 (running for 00:30:53.96)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:08 (running for 00:30:58.99)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:13 (running for 00:31:04.02)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:18 (running for 00:31:09.05)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:23 (running for 00:31:14.10)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:29 (running for 00:31:19.14)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:34 (running for 00:31:24.16)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:39 (running for 00:31:29.19)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:44 (running for 00:31:34.21)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:49 (running for 00:31:39.24)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:54 (running for 00:31:44.26)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:39:59 (running for 00:31:49.30)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:04 (running for 00:31:54.34)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:09 (running for 00:31:59.37)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:14 (running for 00:32:04.40)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:19 (running for 00:32:09.43)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:24 (running for 00:32:14.45)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:29 (running for 00:32:19.49)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:34 (running for 00:32:24.52)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:39 (running for 00:32:29.55)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:44 (running for 00:32:34.58)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: None | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.468553 |     0.8422 |                   15 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.839\n",
            "  date: 2022-03-24_05-40-47\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 16\n",
            "  loss: 0.4737759050290296\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 1953.5762431621552\n",
            "  time_this_iter_s: 121.39092755317688\n",
            "  time_total_s: 1953.5762431621552\n",
            "  timestamp: 1648100447\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 16\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:50 (running for 00:32:40.28)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:40:55 (running for 00:32:45.32)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:00 (running for 00:32:50.34)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:05 (running for 00:32:55.37)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:10 (running for 00:33:00.40)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:15 (running for 00:33:05.43)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:20 (running for 00:33:10.46)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:25 (running for 00:33:15.49)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:30 (running for 00:33:20.55)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:35 (running for 00:33:25.59)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:40 (running for 00:33:30.62)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:45 (running for 00:33:35.65)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:50 (running for 00:33:40.68)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:41:55 (running for 00:33:45.71)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:00 (running for 00:33:50.74)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:05 (running for 00:33:55.76)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:10 (running for 00:34:00.79)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:15 (running for 00:34:05.82)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:20 (running for 00:34:10.85)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:25 (running for 00:34:15.88)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:30 (running for 00:34:20.90)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:35 (running for 00:34:25.93)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:40 (running for 00:34:30.96)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:45 (running for 00:34:35.99)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.473776 |      0.839 |                   16 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8397\n",
            "  date: 2022-03-24_05-42-49\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 17\n",
            "  loss: 0.4713135501191874\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2075.5162360668182\n",
            "  time_this_iter_s: 121.93999290466309\n",
            "  time_total_s: 2075.5162360668182\n",
            "  timestamp: 1648100569\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 17\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:51 (running for 00:34:41.23)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:42:56 (running for 00:34:46.26)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:01 (running for 00:34:51.29)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:06 (running for 00:34:56.32)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:11 (running for 00:35:01.36)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:16 (running for 00:35:06.40)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:21 (running for 00:35:11.42)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:26 (running for 00:35:16.45)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:31 (running for 00:35:21.48)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:36 (running for 00:35:26.51)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:41 (running for 00:35:31.55)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:46 (running for 00:35:36.57)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:51 (running for 00:35:41.60)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:43:56 (running for 00:35:46.63)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:01 (running for 00:35:51.66)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:06 (running for 00:35:56.69)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:11 (running for 00:36:01.72)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:16 (running for 00:36:06.75)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:21 (running for 00:36:11.78)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:26 (running for 00:36:16.81)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:31 (running for 00:36:21.84)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:36 (running for 00:36:26.89)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:41 (running for 00:36:31.96)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:46 (running for 00:36:36.99)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.471314 |     0.8397 |                   17 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8439\n",
            "  date: 2022-03-24_05-44-48\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 18\n",
            "  loss: 0.4701056715789115\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2195.397650241852\n",
            "  time_this_iter_s: 119.88141417503357\n",
            "  time_total_s: 2195.397650241852\n",
            "  timestamp: 1648100688\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 18\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:51 (running for 00:36:42.11)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:44:57 (running for 00:36:47.14)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:02 (running for 00:36:52.18)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:07 (running for 00:36:57.21)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:12 (running for 00:37:02.24)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:17 (running for 00:37:07.27)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:22 (running for 00:37:12.30)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:27 (running for 00:37:17.34)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:32 (running for 00:37:22.37)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:37 (running for 00:37:27.42)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:42 (running for 00:37:32.46)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:47 (running for 00:37:37.49)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:52 (running for 00:37:42.52)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:45:57 (running for 00:37:47.54)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:02 (running for 00:37:52.57)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:07 (running for 00:37:57.60)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:12 (running for 00:38:02.63)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:17 (running for 00:38:07.66)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:22 (running for 00:38:12.69)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:27 (running for 00:38:17.72)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:32 (running for 00:38:22.75)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:37 (running for 00:38:27.77)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:42 (running for 00:38:32.80)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:47 (running for 00:38:37.82)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.470106 |     0.8439 |                   18 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8452\n",
            "  date: 2022-03-24_05-46-51\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 19\n",
            "  loss: 0.4553415800925273\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2317.8477437496185\n",
            "  time_this_iter_s: 122.45009350776672\n",
            "  time_total_s: 2317.8477437496185\n",
            "  timestamp: 1648100811\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 19\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:53 (running for 00:38:43.55)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:46:58 (running for 00:38:48.57)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:03 (running for 00:38:53.61)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:08 (running for 00:38:58.64)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:13 (running for 00:39:03.69)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:18 (running for 00:39:08.72)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:23 (running for 00:39:13.75)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:28 (running for 00:39:18.77)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:33 (running for 00:39:23.80)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:38 (running for 00:39:28.83)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:43 (running for 00:39:33.86)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:48 (running for 00:39:38.90)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:53 (running for 00:39:43.96)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:47:58 (running for 00:39:48.99)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:03 (running for 00:39:54.03)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:08 (running for 00:39:59.05)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:13 (running for 00:40:04.09)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:18 (running for 00:40:09.11)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:24 (running for 00:40:14.16)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:29 (running for 00:40:19.20)\n",
            "Memory usage on this node: 4.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:34 (running for 00:40:24.23)\n",
            "Memory usage on this node: 4.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:39 (running for 00:40:29.26)\n",
            "Memory usage on this node: 4.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:44 (running for 00:40:34.29)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:49 (running for 00:40:39.31)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.455342 |     0.8452 |                   19 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8485\n",
            "  date: 2022-03-24_05-48-53\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 20\n",
            "  loss: 0.44062046051784687\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2439.4984147548676\n",
            "  time_this_iter_s: 121.65067100524902\n",
            "  time_total_s: 2439.4984147548676\n",
            "  timestamp: 1648100933\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 20\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:48:55 (running for 00:40:45.23)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:00 (running for 00:40:50.26)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:05 (running for 00:40:55.30)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:10 (running for 00:41:00.33)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:15 (running for 00:41:05.36)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:20 (running for 00:41:10.39)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:25 (running for 00:41:15.42)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:30 (running for 00:41:20.45)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:35 (running for 00:41:25.48)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:40 (running for 00:41:30.51)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:45 (running for 00:41:35.53)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:50 (running for 00:41:40.58)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:49:55 (running for 00:41:45.61)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:00 (running for 00:41:50.64)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:05 (running for 00:41:55.67)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:10 (running for 00:42:00.69)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:15 (running for 00:42:05.72)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:20 (running for 00:42:10.75)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:25 (running for 00:42:15.78)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:30 (running for 00:42:20.80)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:35 (running for 00:42:25.86)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:40 (running for 00:42:30.92)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:45 (running for 00:42:35.95)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:50 (running for 00:42:40.97)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |    loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.44062 |     0.8485 |                   20 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |         |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |         |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |         |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+---------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8525\n",
            "  date: 2022-03-24_05-50-54\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 21\n",
            "  loss: 0.4367888193031785\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2561.433689594269\n",
            "  time_this_iter_s: 121.93527483940125\n",
            "  time_total_s: 2561.433689594269\n",
            "  timestamp: 1648101054\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 21\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:50:56 (running for 00:42:46.14)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:01 (running for 00:42:51.17)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:06 (running for 00:42:56.20)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:11 (running for 00:43:01.23)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:16 (running for 00:43:06.27)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:21 (running for 00:43:11.29)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:26 (running for 00:43:16.33)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:31 (running for 00:43:21.35)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:36 (running for 00:43:26.39)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:41 (running for 00:43:31.41)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:46 (running for 00:43:36.45)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:51 (running for 00:43:41.48)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:51:56 (running for 00:43:46.52)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:01 (running for 00:43:51.57)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:06 (running for 00:43:56.60)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:11 (running for 00:44:01.62)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:16 (running for 00:44:06.65)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:21 (running for 00:44:11.69)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:26 (running for 00:44:16.71)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:31 (running for 00:44:21.75)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:36 (running for 00:44:26.79)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:41 (running for 00:44:31.82)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:46 (running for 00:44:36.85)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:51 (running for 00:44:41.89)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.436789 |     0.8525 |                   21 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "Result for train_cifar_65f1b_00000:\n",
            "  accuracy: 0.8603\n",
            "  date: 2022-03-24_05-52-54\n",
            "  done: false\n",
            "  experiment_id: 9daf3a9797f441e4a8913d7860e01f05\n",
            "  hostname: 99e6599b0944\n",
            "  iterations_since_restore: 22\n",
            "  loss: 0.4174211883241204\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 13062\n",
            "  should_checkpoint: true\n",
            "  time_since_restore: 2681.2721531391144\n",
            "  time_this_iter_s: 119.83846354484558\n",
            "  time_total_s: 2681.2721531391144\n",
            "  timestamp: 1648101174\n",
            "  timesteps_since_restore: 0\n",
            "  training_iteration: 22\n",
            "  trial_id: 65f1b_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:52:56 (running for 00:44:46.97)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:01 (running for 00:44:52.00)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:06 (running for 00:44:57.03)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:11 (running for 00:45:02.08)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:16 (running for 00:45:07.11)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:22 (running for 00:45:12.16)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:27 (running for 00:45:17.18)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:32 (running for 00:45:22.21)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:37 (running for 00:45:27.26)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2022-03-24 05:53:42 (running for 00:45:32.29)\n",
            "Memory usage on this node: 4.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 16.000: -0.4737759050290296 | Iter 8.000: -0.6050067815431364 | Iter 4.000: -0.7700059138665534 | Iter 2.000: -1.0408213484059474 | Iter 1.000: -1.2569730198307403\n",
            "Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.03 GiB heap, 0.0/3.51 GiB objects (0.0/1.0 accelerator_type:K80)\n",
            "Result logdir: /root/ray_results/train_cifar_2022-03-24_05-08-09\n",
            "Number of trials: 7/7 (6 PENDING, 1 RUNNING)\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "| Trial name              | status   | loc              |         lr |   batch_size | optimizer   |     loss |   accuracy |   training_iteration |\n",
            "|-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------|\n",
            "| train_cifar_65f1b_00000 | RUNNING  | 172.28.0.2:13062 | 0.00225529 |           64 | sgd         | 0.417421 |     0.8603 |                   22 |\n",
            "| train_cifar_65f1b_00001 | PENDING  |                  | 0.0247427  |          256 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00002 | PENDING  |                  | 0.00212884 |          128 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00003 | PENDING  |                  | 0.00240215 |           16 | sgd         |          |            |                      |\n",
            "| train_cifar_65f1b_00004 | PENDING  |                  | 0.0096078  |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00005 | PENDING  |                  | 0.00813447 |          128 | adam        |          |            |                      |\n",
            "| train_cifar_65f1b_00006 | PENDING  |                  | 0.00151213 |          128 | sgd         |          |            |                      |\n",
            "+-------------------------+----------+------------------+------------+--------------+-------------+----------+------------+----------------------+\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OF4QjTDFxyiT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy_of_DL_MP1_(1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}